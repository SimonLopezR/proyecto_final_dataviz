{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el mundo del análisis de datos y el modelado predictivo, una parte fundamental es comprender en detalle la naturaleza y el comportamiento de los datos con los que estamos trabajando ya que serán el insumo del entrenamiento del modelo. Esto se logra mediante un Análisis Exploratorio de Datos (EDA, por sus siglas en inglés), que nos permite examinar las características de nuestros datos, tanto numéricas como categóricas, y comprender su distribución, tendencias y posibles relaciones entre variables. Esta exploración inicial es crucial para tomar decisiones informadas sobre cómo proceder con el modelado y la predicción.\n",
    "\n",
    "Además de la exploración de los datos, también nos proponemos seleccionar los modelos de clasificación más adecuados para nuestro conjunto de datos. Para lograr esto, evaluaremos el rendimiento de tres modelos ampliamente utilizados en la clasificación: Support Vector Machines (SVM), Random Forest Classifier y Gradient Boosting Trees. Estos modelos ofrecen enfoques diferentes para la clasificación y pueden adaptarse a una variedad de situaciones y tipos de datos. En este caso, para sacar la probabilidad de dicha clasificación, que al final de cuentas es el enfoque del proyecto\n",
    "\n",
    "El proceso de selección de modelos implica entrenar y evaluar cada modelo utilizando métricas específicas, como la precisión (accuracy) y el recall. Además, exploraremos diferentes combinaciones de hiperparámetros para cada modelo, con el objetivo de encontrar la configuración óptima que maximice el rendimiento predictivo.\n",
    "\n",
    "En resumen, este informe tiene como objetivo realizar un análisis exhaustivo de nuestros datos mediante un EDA detallado, seguido de la selección y evaluación de modelos de clasificación para predecir con precisión las etiquetas de clasificación, y posteriormente su probabilidad. Al finalizar, esperamos haber obtenido una comprensión profunda de nuestros datos y haber identificado el modelo o modelos que mejor se ajusten a nuestras necesidades de predicción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC  # Para clasificación SVM\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_origen='C:/Users/Pc Com/Documents'\n",
    "ruta_data = os.path.join(ruta_origen, 'final_transactions_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(ruta_data #,parse_dates=['date_BUY_fix','date_SELL_fix'],date_format='ISO8601'\n",
    "               )\n",
    "df=df.loc[:, ~df.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>sector</th>\n",
       "      <th>horizon (days)</th>\n",
       "      <th>amount</th>\n",
       "      <th>date_BUY_fix</th>\n",
       "      <th>date_SELL_fix</th>\n",
       "      <th>price_BUY</th>\n",
       "      <th>price_SELL</th>\n",
       "      <th>Volatility_Buy</th>\n",
       "      <th>Volatility_sell</th>\n",
       "      <th>...</th>\n",
       "      <th>investment</th>\n",
       "      <th>ESG_ranking</th>\n",
       "      <th>PE_ratio</th>\n",
       "      <th>EPS_ratio</th>\n",
       "      <th>PS_ratio</th>\n",
       "      <th>PB_ratio</th>\n",
       "      <th>NetProfitMargin_ratio</th>\n",
       "      <th>current_ratio</th>\n",
       "      <th>roa_ratio</th>\n",
       "      <th>roe_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBY</td>\n",
       "      <td>RETAIL</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>2017-05-26</td>\n",
       "      <td>55.551804</td>\n",
       "      <td>53.483913</td>\n",
       "      <td>0.383666</td>\n",
       "      <td>0.385748</td>\n",
       "      <td>...</td>\n",
       "      <td>BAD</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.58</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0.38</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.49</td>\n",
       "      <td>8.69</td>\n",
       "      <td>26.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAC</td>\n",
       "      <td>BANK</td>\n",
       "      <td>330</td>\n",
       "      <td>15000</td>\n",
       "      <td>2016-11-22</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>18.616749</td>\n",
       "      <td>24.654472</td>\n",
       "      <td>0.322809</td>\n",
       "      <td>0.236350</td>\n",
       "      <td>...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>26.3</td>\n",
       "      <td>11.39</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.71</td>\n",
       "      <td>0.54</td>\n",
       "      <td>15.70</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.67</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AXP</td>\n",
       "      <td>BANK</td>\n",
       "      <td>7</td>\n",
       "      <td>3000</td>\n",
       "      <td>2016-09-27</td>\n",
       "      <td>2016-10-04</td>\n",
       "      <td>59.862297</td>\n",
       "      <td>59.517727</td>\n",
       "      <td>0.238642</td>\n",
       "      <td>0.235491</td>\n",
       "      <td>...</td>\n",
       "      <td>BAD</td>\n",
       "      <td>19.8</td>\n",
       "      <td>10.58</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.60</td>\n",
       "      <td>15.68</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.39</td>\n",
       "      <td>25.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KSS</td>\n",
       "      <td>RETAIL</td>\n",
       "      <td>5</td>\n",
       "      <td>20000</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-17</td>\n",
       "      <td>38.216724</td>\n",
       "      <td>35.985329</td>\n",
       "      <td>0.428559</td>\n",
       "      <td>0.429340</td>\n",
       "      <td>...</td>\n",
       "      <td>BAD</td>\n",
       "      <td>12.9</td>\n",
       "      <td>11.09</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.41</td>\n",
       "      <td>11.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPM</td>\n",
       "      <td>BANK</td>\n",
       "      <td>360</td>\n",
       "      <td>15000</td>\n",
       "      <td>2015-03-12</td>\n",
       "      <td>2016-03-07</td>\n",
       "      <td>51.869335</td>\n",
       "      <td>52.047966</td>\n",
       "      <td>0.194612</td>\n",
       "      <td>0.254011</td>\n",
       "      <td>...</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>27.9</td>\n",
       "      <td>9.38</td>\n",
       "      <td>5.46</td>\n",
       "      <td>1.87</td>\n",
       "      <td>0.81</td>\n",
       "      <td>19.91</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.81</td>\n",
       "      <td>8.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  company  sector  horizon (days)  amount date_BUY_fix date_SELL_fix  \\\n",
       "0     BBY  RETAIL               2     100   2017-05-25    2017-05-26   \n",
       "1     BAC    BANK             330   15000   2016-11-22    2017-10-18   \n",
       "2     AXP    BANK               7    3000   2016-09-27    2016-10-04   \n",
       "3     KSS  RETAIL               5   20000   2016-10-11    2016-10-17   \n",
       "4     JPM    BANK             360   15000   2015-03-12    2016-03-07   \n",
       "\n",
       "   price_BUY  price_SELL  Volatility_Buy  Volatility_sell  ...  investment  \\\n",
       "0  55.551804   53.483913        0.383666         0.385748  ...         BAD   \n",
       "1  18.616749   24.654472        0.322809         0.236350  ...        GOOD   \n",
       "2  59.862297   59.517727        0.238642         0.235491  ...         BAD   \n",
       "3  38.216724   35.985329        0.428559         0.429340  ...         BAD   \n",
       "4  51.869335   52.047966        0.194612         0.254011  ...        GOOD   \n",
       "\n",
       "   ESG_ranking  PE_ratio  EPS_ratio PS_ratio  PB_ratio  NetProfitMargin_ratio  \\\n",
       "0         12.0     12.58       3.73     0.38      3.19                   3.01   \n",
       "1         26.3     11.39       1.26     1.71      0.54                  15.70   \n",
       "2         19.8     10.58       5.64     1.67      2.60                  15.68   \n",
       "3         12.9     11.09       3.27     0.36      1.25                   3.17   \n",
       "4         27.9      9.38       5.46     1.87      0.81                  19.91   \n",
       "\n",
       "   current_ratio  roa_ratio  roe_ratio  \n",
       "0           1.49       8.69      26.69  \n",
       "1           0.92       0.67       5.54  \n",
       "2           1.91       3.39      25.78  \n",
       "3           1.60       4.41      11.35  \n",
       "4           0.99       0.81       8.91  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(n=100,replace=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 25 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   index                     100 non-null    int64  \n",
      " 1   company                   100 non-null    object \n",
      " 2   sector                    100 non-null    object \n",
      " 3   horizon (days)            100 non-null    int64  \n",
      " 4   amount                    100 non-null    int64  \n",
      " 5   date_BUY_fix              100 non-null    object \n",
      " 6   date_SELL_fix             100 non-null    object \n",
      " 7   price_BUY                 100 non-null    float64\n",
      " 8   price_SELL                100 non-null    float64\n",
      " 9   Volatility_Buy            100 non-null    float64\n",
      " 10  Volatility_sell           100 non-null    float64\n",
      " 11  Sharpe Ratio              100 non-null    float64\n",
      " 12  expected_return (yearly)  100 non-null    float64\n",
      " 13  inflation                 100 non-null    float64\n",
      " 14  nominal_return            100 non-null    float64\n",
      " 15  investment                100 non-null    object \n",
      " 16  ESG_ranking               100 non-null    float64\n",
      " 17  PE_ratio                  100 non-null    float64\n",
      " 18  EPS_ratio                 100 non-null    float64\n",
      " 19  PS_ratio                  100 non-null    float64\n",
      " 20  PB_ratio                  100 non-null    float64\n",
      " 21  NetProfitMargin_ratio     100 non-null    float64\n",
      " 22  current_ratio             100 non-null    float64\n",
      " 23  roa_ratio                 100 non-null    float64\n",
      " 24  roe_ratio                 100 non-null    float64\n",
      "dtypes: float64(17), int64(3), object(5)\n",
      "memory usage: 19.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                       0\n",
       "company                     0\n",
       "sector                      0\n",
       "horizon (days)              0\n",
       "amount                      0\n",
       "date_BUY_fix                0\n",
       "date_SELL_fix               0\n",
       "price_BUY                   0\n",
       "price_SELL                  0\n",
       "Volatility_Buy              0\n",
       "Volatility_sell             0\n",
       "Sharpe Ratio                0\n",
       "expected_return (yearly)    0\n",
       "inflation                   0\n",
       "nominal_return              0\n",
       "investment                  0\n",
       "ESG_ranking                 0\n",
       "PE_ratio                    0\n",
       "EPS_ratio                   0\n",
       "PS_ratio                    0\n",
       "PB_ratio                    0\n",
       "NetProfitMargin_ratio       0\n",
       "current_ratio               0\n",
       "roa_ratio                   0\n",
       "roe_ratio                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_var_erase=['company','date_BUY_fix','date_SELL_fix']\n",
    "dependent_var='investment'\n",
    "independent_var=[x for x in df.columns if x not in independent_var_erase and x not in dependent_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables categoricas:  ['sector']\n",
      "Variables numericas:  ['index', 'horizon (days)', 'amount', 'price_BUY', 'price_SELL', 'Volatility_Buy', 'Volatility_sell', 'Sharpe Ratio', 'expected_return (yearly)', 'inflation', 'nominal_return', 'ESG_ranking', 'PE_ratio', 'EPS_ratio', 'PS_ratio', 'PB_ratio', 'NetProfitMargin_ratio', 'current_ratio', 'roa_ratio', 'roe_ratio']\n",
      "Variables independientes:  ['sector', 'index', 'horizon (days)', 'amount', 'price_BUY', 'price_SELL', 'Volatility_Buy', 'Volatility_sell', 'Sharpe Ratio', 'expected_return (yearly)', 'inflation', 'nominal_return', 'ESG_ranking', 'PE_ratio', 'EPS_ratio', 'PS_ratio', 'PB_ratio', 'NetProfitMargin_ratio', 'current_ratio', 'roa_ratio', 'roe_ratio']\n"
     ]
    }
   ],
   "source": [
    "X=df[independent_var]\n",
    "y=df[dependent_var]\n",
    "\n",
    "# Seleccionar columnas categoricas\n",
    "VAR_categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "\n",
    "# Seleccionar columnas numericas\n",
    "VAR_numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Total de columnas\n",
    "VAR_cols = VAR_categorical_cols + VAR_numerical_cols\n",
    "\n",
    "print('Variables categoricas: ',VAR_categorical_cols)\n",
    "print('Variables numericas: ',VAR_numerical_cols)\n",
    "print('Variables independientes: ',VAR_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los preprocesadores:\n",
    "# La funcion ColumnTransformer() nos permite aplicar otras funciones en un orden logico, y sobre qué columnas aplicarlas\n",
    "# acá como ponemos ver aplicamos el codificacion numerica ordenada a las variables categoricas y escalamiento estandarizado\n",
    "# a las numericas\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OrdinalEncoder(), VAR_categorical_cols)\n",
    "        #,('num', StandardScaler(), VAR_numerical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'SVC': SVC(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 4: Define un diccionario de parámetros para cada clasificador\n",
    "param_grid = {\n",
    "    'SVC': {'classifier__C': [1, 10], 'classifier__kernel': ['linear', 'rbf'],'classifier__gamma':[ 1, 10]},\n",
    "    'RandomForestClassifier': {'classifier__n_estimators': [50, 100], 'classifier__max_depth': [None, 10],'classifier__min_samples_split': [5, 10]},\n",
    "    'GradientBoostingClassifier': {'classifier__n_estimators': [50, 100], 'classifier__learning_rate': [0.01, 0.1]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 5: Define un diccionario de pipelines\n",
    "pipelines = {}\n",
    "for name, classifier in classifiers.items():\n",
    "    pipelines[name] = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy en training -> SVC: best training score 0.675, modelo ganador Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('cat', OrdinalEncoder(),\n",
      "                                                  ['sector'])])),\n",
      "                ('classifier', SVC(C=0.1, gamma=0.1, kernel='linear'))])\n",
      "accuracy en training -> RandomForestClassifier: best training score 0.975, modelo ganador Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('cat', OrdinalEncoder(),\n",
      "                                                  ['sector'])])),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(max_depth=20, min_samples_split=5,\n",
      "                                        n_estimators=200))])\n",
      "accuracy en training -> GradientBoostingClassifier: best training score 0.9875, modelo ganador Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('cat', OrdinalEncoder(),\n",
      "                                                  ['sector'])])),\n",
      "                ('classifier',\n",
      "                 GradientBoostingClassifier(learning_rate=0.01,\n",
      "                                            n_estimators=50))])\n"
     ]
    }
   ],
   "source": [
    "# Paso 6: Utiliza GridSearchCV para buscar los mejores parámetros\n",
    "best_models = {}\n",
    "training_accuracies = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    grid_search2 = GridSearchCV(pipeline, param_grid[name], cv=5,scoring='accuracy')\n",
    "    grid_search2.fit(X_train, y_train)\n",
    "    msg_training=f\"accuracy en training -> {name}: best training score {grid_search2.best_score_}, modelo ganador {grid_search2.best_estimator_}\"\n",
    "    print(msg_training)\n",
    "    best_models[name] = grid_search2.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
